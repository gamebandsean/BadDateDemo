# Implement Tests

Implements the actual test code based on test specifications created by `write-failing-tests`, making the tests pass by ensuring the code works correctly.

## Overview

This command takes test specifications generated by `write-failing-tests` and implements the actual test code. The tests should initially fail (as specified), and then the command ensures the implementation is correct so the tests pass.

**Important**: This command should:
- Implement test code based on test specifications
- Use the project's testing framework and conventions
- Ensure tests are properly structured and maintainable
- Make tests pass by fixing implementation if needed
- NOT modify test specifications (those come from `write-failing-tests`)
- Follow test-driven development principles where appropriate

## Steps

1. **Locate Test Specifications**
   - Look for test specification files in `docs/tests/` folder
   - If a specific test specification file is provided, use that
   - If a task is provided, look for corresponding test specifications
   - If no specifications are found, ask the user to either:
     - Run `write-failing-tests` first to create test specifications
     - Provide the path to test specification files
     - Provide test specifications directly

2. **Read Test Specifications**
   - Read the test specification file completely
   - Understand all test scenarios to implement
   - Note test priorities and categories
   - Understand expected behaviors and current states
   - Identify test dependencies and setup requirements

3. **Locate Code Under Test**
   - Find the code files that need to be tested
   - Read the implementation code
   - Understand the code structure and public interface
   - Identify dependencies that need to be mocked
   - Understand the testing context and requirements

4. **Check Testing Framework**
   - Identify the testing framework used in the project
   - Check existing test files for patterns and conventions
   - Understand test file organization and naming
   - Check for existing test utilities or helpers
   - Understand mocking/stubbing approaches used
   - If no testing framework is set up, ask the user which framework to use

5. **Plan Test Implementation**
   - Organize tests by component/class
   - Group related tests together
   - Plan test setup and teardown
   - Identify what needs to be mocked
   - Plan test data and fixtures
   - Consider test execution order if relevant

6. **Create Test Files**
   - Create test files following project conventions
   - Use appropriate naming (e.g., `[Component]Tests.cs`, `test_[component].py`)
   - Place tests in appropriate test directories
   - Organize tests to match code structure
   - Create necessary test fixtures or data files

7. **Implement Test Code**
   - For each test specification:
     - Write the test method/function
     - Set up test data and mocks
     - Implement test assertions
     - Add appropriate test documentation
   - Follow the project's test patterns
   - Use descriptive test names matching specifications
   - Implement test setup and teardown
   - Add necessary test utilities or helpers

8. **Run Tests (If Possible)**
   - Attempt to run the tests
   - Check which tests fail and why
   - Verify that tests fail for the expected reasons (as per specifications)
   - Note any issues with test implementation

9. **Fix Implementation to Make Tests Pass**
   - If tests fail due to implementation issues (not test issues):
     - Identify what's wrong with the implementation
     - Fix the implementation code
     - Ensure fixes don't break other functionality
     - Re-run tests to verify fixes
   - If tests fail due to test code issues:
     - Fix the test implementation
     - Ensure tests correctly verify the behavior
   - Continue until all tests pass

10. **Verify Test Coverage**
    - Ensure all test specifications are implemented
    - Check that tests cover all important scenarios
    - Verify edge cases are tested
    - Check that error conditions are tested
    - Identify any gaps in test coverage

11. **Update Test Specifications**
    - Update test specification file to mark implemented tests
    - Note which tests pass and which were modified
    - Document any deviations from original specifications
    - Note any additional tests that were added

12. **Update Task Status**
    - Update the task status in the task file
    - Mark testing-related subtasks as complete
    - Note that tests have been implemented and are passing

13. **Update Changelog**
    - Read the existing `CHANGELOG.md` file (create if it doesn't exist)
    - Append a new entry at the top with:
      - Current date and time (ISO 8601 format: YYYY-MM-DD HH:MM:SS)
      - Command name: `implement-tests`
      - Files changed: List the created test files
    - Format: `[YYYY-MM-DD HH:MM:SS] implement-tests: Created [list of test files]`
    - Keep entries minimal and chronological (newest first)

## Test Implementation Guidelines

- **Follow Specifications**: Implement tests exactly as specified
- **Use Framework Conventions**: Follow the project's testing patterns
- **Clear Test Names**: Use descriptive names that explain what's tested
- **Proper Setup**: Set up test data and mocks correctly
- **Good Assertions**: Use clear, specific assertions
- **Isolation**: Tests should be independent and not affect each other
- **Maintainability**: Tests should be easy to understand and modify

## Notes

- Tests should initially fail if that's what the specifications indicate
- Implementation should be fixed to make tests pass
- Test code should be as clean and maintainable as production code
- All test specifications should be implemented
- Tests should verify both positive and negative cases

